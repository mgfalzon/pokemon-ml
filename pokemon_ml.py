# -*- coding: utf-8 -*-
"""Pokemon-ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cr73mcn6jcUh6J13w8-tuZT-SbCL7ppR

# <center>Predicting Pokemon Battles</center>
<center>Matt Falzon, Robert Calkins, Michael Bailey</center>

<p align="center">
    <img src="https://raw.githubusercontent.com/mgfalzon/pokemon-ml/main/all_pokemons.png" width="500" height="300">
</p>

### <b>What are Pokémon?</b> <br>

<p>
Pokémon is a video game franchise centered around fictional creatures called 'pokémon' which humans catch, train, and battle for sport. In the game, the player is tasked with building a team of strong pokémon which they will use to challenge other 'pokemon trainers'.
</p>

<p>
Each pokémon has a unique look, typing, and a set of base stats. Each pokémon can be identified by their unique pokédex number. The typing follows a rock-paper-scissors like mechanic where, for example, a pokémon of type water has an advantage over a pokémon of type fire. The stats determine how much health, strength and speed a pokémon might have. Since each pokémon is different it can be hard to tell without experience which would have an edge over another in a battle.
</p>

### <b>Project Goals</b>

<p>
This tutorial seeks to explore the relationship between a pokémon's characteristics and win percentage in around 100 simulated battles. In order to preform our analysis we'll be looking at 3 characterstics, a pokémon's type, their base stats, and finally their legendary status. We want to know if we can use these characterstics in order to predict the outcome of future battles. The Kaggle dataset 'Pokemon-Weedle's Cave' by user <a href="https://www.kaggle.com/terminus7">terminus7</a> contains two files which will be used to preform our analysis. The first file contains the pokémon charactersitics and the second one contains information about previous battles.
</p>


### <b>Technology</b>

In this tutorial we'll be using the following python libraries. Feel free to follow these links to learn more!

- [requests](https://requests.readthedocs.io/en/master/)
- [json](https://docs.python.org/3/library/json.html)
- [pandas](https://pandas.pydata.org/)
- [numpy](https://numpy.org/)
- [matplotlib](https://matplotlib.org/)
- [seaborn](https://seaborn.pydata.org/)
- [Sci-Kit Learn](https://scikit-learn.org/stable/)
"""

import requests
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## Data Collection

We are using a dataset found on kaggle. You can find and download the CSV here: 

[Pokémon Weedle's Cave](https://www.kaggle.com/terminus7/pokémon-challenge)

#### Data Size and Content

<p>
This dataset contains two csv files. One contains entries for all 800 pokémon listed in the generation 6 Pokédex(a digital encyclopedia of information about pokémon). Each pokémon has 6 base stats and 1 or 2 types. The table also records each pokémon's generation(which set of games a pokémon first appeared in) and their legendary status. 

The other dataset contains 50,000 simulated battles. The first two columns contain the ids of the combatants and the third one column contains the id of the winner. The pokémon in the first column attacked first.
</p>
"""

path = "https://raw.githubusercontent.com/mgfalzon/Final-Tutorial/main"
combats = pd.read_csv(f"{path}/combats.csv")
pokemon = pd.read_csv(f"{path}/pokemon.csv")

pokemon.head()

combats.head()

"""## Data Processing

### Tidy up Pokémon

<p>
Now that we know what our data represents, let's take a closer look at the pokémon table ensure that none of the data is missing.
</p>
"""

pokemon.isna().sum()

"""<p>It turns out we have one pokémon that is missing its name. Before we continue we should try to identify this pokémon in order to complete our dataset. We can do this by finding the index, making a call to an existing API, and extracting the relevant information.</p>"""

missing = pokemon[pokemon['Name'].isna()]
missing

# Take a look at the surrounding Pokemon
miss_id = missing.index[0]
pokemon[miss_id - 2 : miss_id + 2]

"""<p>
The missing pokemon follows Mankey in our dataset, and has the same type as Mankey. Based on these observations our missing pokemon and Mankey might be related.

In order to identify our missing pokemon, let's make use of the <a href="https://pokeapi.co/">PokeAPI</a>. The PokeAPI is a <a href="https://en.wikipedia.org/wiki/Representational_state_transfer">RESTful API</a> containing data about all the pokemon games. If we identify the pokemon after Mankey in the pokeAPI we should be able to find our missing pokemon. 
</p>
"""

# pokeAPI to fetch pokemon data
def pokeAPI(s):
    r = requests.get(f"https://pokeapi.co/api/v2/pokemon/{s}")
    return json.loads(r.content)

# Check the pokemon after Mankey in the pokeAPI
res = pokeAPI('mankey')
res = pokeAPI(res['id'] + 1)
display(res['name'], res['types'], res['stats'])

# Clean stats for readability
data = {stat['stat']['name'] : stat['base_stat'] for stat in res['stats']}
data['type'] = res['types'][0]['type']['name']
df = pd.DataFrame(data, [res['name']])
display("pokeAPI Data", df)
display("Pokemon Data", missing.iloc[:,1:10])

# Update the data
pokemon['Name'] = np.where(pokemon['Name'].isna(), 'Primeape', pokemon['Name'])
pokemon[miss_id - 2 : miss_id + 2]

"""### Continuity between Combats and Pokémon

<p>
Our next step is to ensure that no data is missing from the combats dataset. We also need to make sure every pokémon in our pokémon table is represented in the combats table. We can check this by comparing the number of unique pokémon with the number of unique winners and losers.
</p>

"""

#Check if we have any missing data (We dont)
combats.isna().sum()

# Insert Loser column for simplification
combats['Loser'] = pd.Series(np.where(combats['Winner'] == combats['First_pokemon'], combats['Second_pokemon'], combats['First_pokemon']))
combats.head(3)

# Get # of unique pokemon, winners, losers
all_pokemon = np.unique(pokemon['#'])
winners = np.unique(combats['Winner'])
losers = np.unique(combats['Loser'])

# Verify that each pokemon has at least one loss and one win
print(f"Total Pokemon: {len(all_pokemon)}")
print(f"Unqiue Winners: {len(winners)}")
print(f"Unqiue Losers: {len(losers)}")

"""#### A disconnect

<p>
There's 17 pokemon missing from our winners column and 16 pokemon missing from our loser column. It's possible that certain pokemon have no wins while others have no losses, so let's see if any of these pokemon don't appear as either winners or losers. If they do not, we will drop them from the table as they won't provide any insight for our analysis.
</p>
"""

# Pokemon that did not win or lose (these pokemon did not compete)
ids = [x for x in all_pokemon if x not in winners and x not in losers]
display(ids, pokemon[pokemon['#'].isin(ids)].head())

# Let's drop those pokemon, they won't provide insight for our analysis
pokemon = pokemon[~pokemon['#'].isin(ids)]

"""While we removed all the Pokemon with no wins and no losses there is still one Pokemon with no wins. Lets find out who it is."""

# Pokemon with no wins
worst_pokemon = [x for x in pokemon['#'] if x in losers and x not in winners][0]
pokemon[pokemon['#'] == worst_pokemon]

# Get # of unique pokemon, winners, losers
all_pokemon = np.unique(pokemon['#'])
winners = np.unique(combats['Winner'])
losers = np.unique(combats['Loser'])

# Each pokemon has at least one loss and one win (disregarding Shuckle)
print(f"Total Pokemon: {len(all_pokemon)}")
print(f"Unqiue Winners: {len(winners)}")
print(f"Unqiue Losers: {len(losers)}")

"""## Data Exploration

<p>We know there are 784 competitors with one Pokemon who had 0 wins (sucks to be a Shuckle). We will now explore the complete datasets. 

Let's start by generating the win percentage for each Pokemon.
</p>
"""

# Generate win and loss counts for each pokemon
wins = combats['Winner'].value_counts().sort_index().rename('Wins')
loss = combats['Loser'].value_counts().sort_index().rename('Loss')

# Add 0 to wins for Shuckle
wins[worst_pokemon] = 0

# Calculate win percentage
res = pd.concat([wins, loss], axis=1)
res['win_loss'] = res['Wins'] / (res['Wins'] + res['Loss'])
res['win_pct']  = (res['win_loss'] * 100).round(1)
res.head()

# Join with pokemon table
pokemon = pokemon.join(res, on='#')

# Top 50 Pokemon by win percentage
top50 = pokemon.sort_values(by='win_pct', ascending=False).head(50)
top50[['Name', 'win_pct']].head()

# Bottom 50 Pokemon by win percentage
bot50 = pokemon.sort_values(by='win_pct', ascending=True).head(50)
bot50[['Name', 'win_pct']].head()

# Type frequency
type_freq = pokemon.groupby(by=['Type 1', 'Type 2'], dropna=False)['Name'].count().rename('freq')
type_freq = type_freq.sort_values(ascending=False)
pd.DataFrame(type_freq).head()

# Type frequency in the top 50 pokemon 
type_freq = top50.groupby(by=['Type 1', 'Type 2'], dropna=False)['Name'].count().rename('count').reset_index()
type_freq = type_freq.sort_values(by='count', ascending=False).reset_index(drop=True)
type_freq.head()

# Type frequency in the bottom 50 pokemon
type_freq = bot50.groupby(by=['Type 1', 'Type 2'], dropna=False)['Name'].count().rename('count').reset_index()
type_freq = type_freq.sort_values(by='count', ascending=False).reset_index(drop=True)
type_freq.head()

"""### Whats going on here?

<p>
We just generated a lot of tables. Lets break it down. We first figured out each Pokemons win rate. Turns out Mega Aerodactyle has the highest win rate at 98%. 

We now want to see if any of the top 50 or bottom 50 have any typings in common. The first table uses the dataset as a whole for the control, the most common type seems to be Normal with 59 Pokemon; followed by water. 

The top 50 has Psychic as its most frequent type, while the bottom 50 has Bug as its most frequent type. However, both tables include the basic Psychic and Normal types, so it would be difficult to draw any immediate conclusions from these tables. Even so, it does seem as though there might be a relationship between pokémon type and win percentage. 
</p>

<p>
Next we will visualize the data to see how the Pokemon stats relate to each other and to try and solidify any relationships.
</p>

## Data Visualization

<p>
We saw there was a slight difference in the types of Pokemon within the top 50 and bottom 50 Pokemon. Now we are going to explore the relationships between the stats of Pokemon and their win rate. Below we will graph each Pokemons 6 stats against its win percentage. Yellow dots indicate if a Pokemon is Legendary.
</p>
"""

# Graph Base Stats -- Win Percentage
base_stats = ["HP", "Speed", "Attack", "Sp. Atk", "Defense", "Sp. Def"]
fig, axs = plt.subplots(3, 2, figsize=(20, 20))
pts = [(i, j) for i in range(3) for j in range(2)]

color = np.where(pokemon['Legendary'] == True, 'gold', 'cornflowerblue')
for stat, (x,y) in zip(base_stats, pts):
  
  # Plot stat on subplot
  ax = axs[x, y]
  ax.scatter(stat, "win_pct", data=pokemon, c=color)
  ax.set(title=f'{stat} vs. Win Percentage', xlabel=stat, ylabel='Win Percentage')

  # Line of best fit
  ax.set_ylim(-3,103)
  x,y= pokemon[stat], pokemon['win_pct']
  m,b = np.polyfit(x,y,1)
  ax.plot(x,m*x + b)

"""There is a lot going on here! Lets break down these graphs. First, there is a strong and obvious relationship between a pokémon's speed and its win rate. The Speed vs. Win graph has the steapest line. Attack and Sp. Attack can both be observed to have correlations but not as pronounced as Speed. The other graphs have much weaker correlations.

A second thing to note is the positioning of most of the legendary pokémon. For the most part legendary pokémon are on the top half of each of the graphs. With a few extreme outliers, most of the legendary's are clustered together.

Let's graph the correlation between each of the stats and the win percentage in order to see some more concrete relationships.
"""

# Base stats, legendary status, win_pct
cols = list(pokemon.columns[4:10]) + ['Legendary', 'win_pct']
df = pokemon[cols].rename({'win_pct' : 'Win Percentage'}, axis=1)

# Setup graph
plt.figure(figsize=(12,8))
cmap = sns.color_palette("ch:start=.2,rot=-.3", as_cmap=True)

# Generate heatmap
data = df.corr()['Win Percentage'].sort_values(ascending=False)
sns.heatmap(pd.DataFrame(data), cmap=cmap, annot=True)

# Plot Average Win Percentage Legendary vs Regular
ax = plt.subplot()
res = pokemon.groupby(by="Legendary")['win_pct'].mean().round(2)
ax.bar('Legendary', res[1], color='gold', label=res[1], ec='black')
ax.bar('Regular', res[0], color='cornflowerblue', label=res[0], ec='black')
ax.set_title("Average Win Percentage Between Legendary and Regular Pokemon")
ax.set_ylabel("Average Win Percentage")
ax.legend()

"""These two graphs emphasize what we saw in our initial plots. The heatmap shows a strong correlation between Speed and wins, just like what we saw in the Speed vs Win graph. The Attack and Sp. Atk correlations are not as strong as we would have thought just by looking at the original graphs, still, they are higher then the other stats. 

The bar graph above shows that legendary pokémon have a higher average win percentage then regular pokémon. We observed from the original plots that legendary pokémon seemed to be on the upper half of each plot. This graph verifies that legendary Pokémon have a much higher average win percentage(around 80%).

Finally, let's see if we can conclude anything about the pokémon types and win percentage. We noticed there was a difference in our initial analysis. We can graph a heatmap to try and spot the differences.
"""

from matplotlib import colors
from matplotlib import cm

fig, ax = plt.subplots(figsize=(15,8))

# Custom color mapping for graph
bounds = np.arange(0, 110, 10)
norm = colors.BoundaryNorm(bounds, cm.Blues.N)

# Mean win percentage by Types
df = pokemon.fillna("None")
res = df.groupby(by=["Type 1", "Type 2"], dropna=False)['win_pct'].mean()
df = pd.DataFrame(res)

# Join with type frequency
type_freq = pokemon.groupby(by=['Type 1', 'Type 2'], dropna=False)['Name'].count().rename('freq')
df = df.join(type_freq, on=['Type 1', 'Type 2']).reset_index()

# Graph
df['freq'] *= 10 
im = ax.scatter('Type 2', 'Type 1', c='win_pct', s='freq', norm=norm, cmap='Blues',data=df)
cbar = fig.colorbar(im, ax=ax, label='label')
cbar.set_label('win_pct', rotation=0)

# Axis Labels
ax.set_title('Win Percentage, Frequency by Types')
ax.set(ylabel='Type 1', xlabel='Type 2')

"""This graph shows a lot of differnt data combined together, so it might be difficult to parse. The color represents the win percentage and the size represents the amount of pokémon of a particular type combination. Looking at the graph, there are definietly some outliers. For example, Dark-Ice has a 96% win rate, but a relatively small frequency. One conclusion we might be able to draw from this graph is that a lot of pokémon seem to have Flying as their second type, which has a relatively high win percentage. Fighting as a second type also seems to have an edge. While it might be difficult for us to draw conclusions from this graph, this where machine learning will come in. In the next section we'll train some models and determine how useful these characteristics will be in determining the winner of a simulated battle.

## Machine Learning

<p>
While we have tidied up our data in previous sections. It's not quite ready for a machine learning model just yet.

We want to create a feature set containing two pokémon's characteristics for each battle. This will allow us to train different regression models where the output is either a 0 or 1. 0 will mean the first Pokemon won, and a 1 will mean the second Pokemon won. 

First we will finalize our feature set, which will be denoted "pokemon_ml," and make sure there are no NaN values. 
</p>
"""

pokemon_ml = pokemon.drop(["Name","Generation", "Wins", "Loss", "win_loss", "win_pct"], axis=1)
pokemon_ml.set_index("#", inplace=True)
pokemon_ml["Type 2"].fillna("None", inplace=True)
pokemon_ml.head()

"""### Creating the Feature Set

This is a great start to our ML dataset. We have isolated the features we want to train our model on. Our next step is to encode the types and legendary status. 

ML models would not understand the word "grass" so we are going to use an Ordinal Encoder to convert the types into a range from 0 to 17. Sklearn has a package that does just that. 
"""

from sklearn.preprocessing import OrdinalEncoder

# Encode type1, type2, legendary status
pokemon_cat = pokemon_ml[["Type 1", "Type 2", "Legendary"]]
ordinal_encoder = OrdinalEncoder()
pokemon_cat_encoded = ordinal_encoder.fit_transform(pokemon_cat)

print(pokemon_cat_encoded[:5]) 
print(ordinal_encoder.categories_)

# Update the DataFrame with the encoded values
pokemon_cat_encoded = pd.DataFrame(pokemon_cat_encoded, columns=["Type 1", "Type 2", "Legendary"])
pokemon_cat_encoded.index = pokemon_ml.index 
pokemon_ml["Type 1"] = pokemon_cat_encoded["Type 1"]
pokemon_ml["Type 2"] = pokemon_cat_encoded["Type 2"]
pokemon_ml["Legendary"] = pokemon_cat_encoded["Legendary"]
pokemon_ml.head()

pokemon_ml.isna().sum()

"""Great! Our pokemon_ml feature set is ready to go! There are no NaN values anywhere to be found and we have encoded our data efficiently. We can now join the combats dataset with the features using the pokemon ids to create our final dataset, which can be used with the ML models."""

# Clean up combats: get just the ids and expected output
df = combats.drop('Loser', axis=1)
df.columns = ['P1', 'P2', 'Winner']

# Join the combats and pokemon_ml feature set 
X = df.join(pokemon_ml, on='P1').join(pokemon_ml, on='P2', lsuffix=" P1", rsuffix=" P2")

# Encode the winner to 0 or 1, drop identifiers
X['Winner'] = np.where(X['Winner'] == X['P1'], 0, 1)
X = X.drop(["P1", "P2"], axis=1).reset_index(drop=True)

# Extract the labels/expected output
y = X.pop('Winner')

display("Features: ", X.head())
display("Labels/Expected Output: ", y.head())

"""### Training Models

Our dataset is ready to go. We'll use the dataset to pass 20 or so features into the model which will ouput either a 0 or a 1 signifying the winner. In this tutorial we'll be using sklearns train_test_split method to create our training and testing data. 

We will train a variety of models in order to determine which one produces the most accurate results for our dataset. To start, linear regression will be used as a base line. Since our data is meant for logistic regression, this should produce poor results. Following linear regression we'll try logistic regression, KNN, then finally a decision tree regressor.
"""

# Split data 80:20
from sklearn.model_selection import train_test_split

x_train, x_test , y_train, y_test= train_test_split(X, y, test_size = 0.2)

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(x_train, y_train)
acc_lin= lin_reg.score(x_test, y_test)
print("Linear Regression accuracy:", acc_lin)

"""As expected linear regression had a low accuracy of 47% predicting which pokémon would win in a battle. Lets try out some models which should do a lot better!"""

from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression(max_iter=500)
log_reg.fit(x_train, y_train)
acc_log= log_reg.score(x_test, y_test)
print("Logistic Regression Accuracy: ", acc_log)

"""Great! Logistic Regression did much better! With an accuracy of about 89% this can predict the outcome of two pokemon in battle. It seems pretty good, lets try out a few more models to see if we can do better."""

from sklearn.neighbors import KNeighborsClassifier

for k in range(3, 10, 2):
    knn = KNeighborsClassifier(n_neighbors = k)
    knn.fit(x_train, y_train)
    acc_knn = knn.score(x_test, y_test)
    print("KNN with k=", k, "Accuracy: ", acc_knn)

"""It seems KNN maxes out around 87% accuracy above k=3. """

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(x_train, y_train)
acc_tree = tree_reg.score(x_test, y_test)
print("Decision Tree Regressor Accuracy: ", acc_tree)

"""Woah, this is not the direction we wanted to go in! We can stick with Logistical Regression and KNN for now."""

h = 0.6
c = 'red'

plt.barh(['Logistic Regression'], 1, color = c, alpha = 0.55, height = h)
plt.barh(['Logistic Regression'], acc_log, color = 'yellowgreen', alpha = 1, height = h)

plt.barh(['KNN'], 1, color = c, alpha = 0.55, height = h)
plt.barh(['KNN'], acc_knn, color = 'yellowgreen', alpha = 1, height = h)

plt.barh(['Decision Tree'], 1, color = c, alpha = 0.55, height = h)
plt.barh(['Decision Tree'], acc_tree, color = 'yellowgreen', alpha = 1, height = h)

plt.barh(['Linear Regression'], 1, color = c, alpha = 0.55, height = h)
plt.barh(['Linear Regression'], acc_lin, color = 'yellowgreen', alpha = 1, height = h)

plt.title("Model Accuracy")
plt.legend(['Incorrect\nPrediction', 'Correct\n Prediction'],bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

"""### Conclusion

<p>
With the above models we managed to predict pokémon battles up to 89% accuracy. Logistic Regression and K Nearest Neighbors preformed the best. Based on the model accuracy, there is a relationship between a pokémon's characteristics and their win percentage.

Thank you for following along with our data science tutorial!
</p>
"""